<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>蓝柚青柠</title>
  
  <subtitle>努力学会写好每一行代码。嗯。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-05-26T11:06:09.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>lotus</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka笔记</title>
    <link href="http://yoursite.com/2018/05/26/test/"/>
    <id>http://yoursite.com/2018/05/26/test/</id>
    <published>2018-05-26T02:20:28.000Z</published>
    <updated>2018-05-26T11:06:09.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kafka集群搭建"><a href="#Kafka集群搭建" class="headerlink" title="Kafka集群搭建"></a>Kafka集群搭建</h1><h2 id="1-kafka基本结构"><a href="#1-kafka基本结构" class="headerlink" title="1. kafka基本结构"></a>1. kafka基本结构</h2><p>作为一个消息系统，其基本结构中至少要有产生消息的组件（消息生产者，Producer）以及消费消息的组件（消费者，Consumer)。生产者负责生产消息，将消息写入Kafka集群;消费者从Kafka 集群中拉取消息。</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    生产者1--&gt;kafka集群;</span><br><span class="line">    生产者2--&gt;kafka集群;</span><br><span class="line">    生产者3--&gt;kafka集群;</span><br><span class="line">    kafka集群--&gt;消费者1;</span><br><span class="line">    kafka集群--&gt;消费者2;</span><br><span class="line">    kafka集群--&gt;消费者3;</span><br></pre></td></tr></table></figure><h2 id="2-kafka基本概念"><a href="#2-kafka基本概念" class="headerlink" title="2. kafka基本概念"></a>2. kafka基本概念</h2><p>kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。</p><ol><li><strong>主题</strong><br>Kafka 将一组消息抽象归纳为一个主题（Topic），也就是说，一个主题就是对消息的一个分类。生产者将消息发送到特定主题，消费者订阅主题或主题的某些分区进行消费。</li><li><strong>消息</strong><br>消息是Kafka 通信的基本单位，由一个固定长度的消息头和一个可变长度的消息体构成。</li><li><strong>分区和副本</strong><br>kafka在创建topic时，可以设置所拥有的分区和副本数，也可以在Kafka启动时所加载的配置文件中配置。每个分区在物理上对应为一个文件夹，每个分区又有一至多个副本（Replica），分区的副本分布在集群的不同代理上，以提高可用性。从存储角度上分析，分区的每个副本在逻辑上抽象为一个日志（Log）对象，即分区的副本与日志对象是一一对应的。分区使得Kafka在井发处理上变得更加容易，分区也是Kafka保证消息被顺序消费以及对消息进行负载均衡的基础。</li><li><strong>偏移量</strong><br>任何发布到分区的消息会被直接追加到日志文件（分区目录下以＂.log”为文件名后缀的数据文件〉的尾部，而每条消息在日志文件中的位置都会对应一个按序递增的偏移量。Kafka 几乎不允许对消息进行随机读写，因此Kafka并没有提供额外索引机制到存储偏移量也就是说并不会给偏移量再提供索引。消费者可以通过控制消息偏移量来对消息进行消费，如消费者可以指定消费的起始偏移量。为了保证消息被顺序消费，消费者己消费的消息对应的偏移量也需要保存。</li><li><strong>日志段</strong><br>一个日志又被划分为多个日志段（LogSegment），日志段是Kafka日志对象分片的最小单位。与日志对象一样，日志段也是一个逻辑概念，一个日志段对应磁盘上一个具体日志文件和两个索引文件。日志文件是以“.log”为文件名后缀的数据文件，用于保存消息实际数据。两个索引文件分别以“.index”和“.timeindex”作为文件名后缀，分别表示消息偏移量索引文件和消息时间戳索引文件。</li><li><strong>代理</strong><br>在Kafka 基本体系结构提到了Kafka集群。Kafka集群就是由一个或多个Kafka实例构成，我们将每一个Kafka实例称为代理（Broker），通常也称代理为Kafka 服务器( KafkaServer ）</li><li><strong>生产者</strong><br>生产者（ Producer ）负责将消息发送给代理，也就是向Kafka 代理发送消息的客户端。</li><li><strong>消费者和消费组</strong><br>消费者（ C omsumer ）以拉取（ pull ）方式拉取数据，它是消费的客户端。在Kafka 中每一个消费者都属于一个特定消费组（ConsumerGroup），我们可以为每个消费者指定一个消费组，以groupld 代表消费组名称，通过group.id配置设置。如果不指定消费组，则该消费者属于默认消费组test-consumer-group。同时，每个消费者也有一个全局唯一的id，通过配置项client.id指定，如果客户端没有指定消费者的id,Kafka会自动为该消费者生成一个全局唯一的id 。同一个主题的一条消息只能被同一个消费组下某一个消费者消费，但不同消费组的消费者可同时消费该消息。消费组是Kafka用来实现对一个主题消息进行广播和单播的手段，实现消息广播只需指定各消费者均属于不同的消费组，消息单播则只需让各消费者属于同一个消费组。</li></ol><h2 id="3-kafka集群搭建"><a href="#3-kafka集群搭建" class="headerlink" title="3. kafka集群搭建"></a>3. kafka集群搭建</h2><blockquote><p>搭建步骤默认建立在服务器已配置好java环境以及<strong>搭建好的外部zookeeper集群</strong>。</p></blockquote><p><em>注意：kafka自带zookeeper，应避免其与外部zookeeper发生冲突。</em></p><p>假设搭建好的zookeeper集群环境如下：<br>三个节点名分别为spamaster spaslave1 spaslave2</p><ul><li>192.168.2.161：2181  </li><li>192.168.2.162：2181</li><li>192.168.2.198：2181</li></ul><p>我们同样在161,162,198三个服务器上搭建kafka集群  安装路径/home/hadoop/bigdata/kafka</p><ol><li><p>首先在spamaster节点上准备好安装包 我们选用的kafka版本为  kafka_2.10-0.10.2.1.tgz<br>官网下载地址<a href="http://kafka.apache.org/downloads.html" target="_blank" rel="noopener">http://kafka.apache.org/downloads.html</a></p></li><li><p>将安装包解压到需要存放的目录下，例如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf kafka_2.10-0.10.2.1.tgz -C /home/hadoop/bigdata</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv kafka_2.10-0.10.2.1 kafka</span><br></pre></td></tr></table></figure></li></ol><ol start="3"><li>修改配置文件<br>主要修改的配置文件包括：config目录下的<strong>server.properties</strong>配置文件，这是kafka配置文件<blockquote><p>config下的zookeeper.properties文件，是用来配置kafka自带的zookeeper的，此处我们不需要修改</p></blockquote></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#spamaster节点</span><br><span class="line">#server.properties</span><br><span class="line"></span><br><span class="line">#kafka服务器id</span><br><span class="line">broker.id=0</span><br><span class="line">#开启删除，保证topic被删除时不是仅仅标记删除</span><br><span class="line">delete.topic.enable=true</span><br><span class="line">listeners=PLAINTEXT://spamaster:9092</span><br><span class="line">advertised.listeners=PLAINTEXT://spamaster:9092</span><br><span class="line">num.network.threads=3</span><br><span class="line">num.io.threads=8</span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line">log.dirs=/home/hadoop/bigdata/kafka/logs</span><br><span class="line">num.partitions=1</span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line">log.retention.hours=168</span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line">zookeeper.connect=spamaster:2181,spaslave1:2181,spaslave2:2181</span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br></pre></td></tr></table></figure><p>将配置好的kafka文件夹复制到另外两个spaslave节点相同路径下 server.properties里的如下字段要根据节点修改</p><p><strong>broker</strong>.<strong>id</strong></p><ul><li>spamaster：0  </li><li>spaslave1：1 </li><li>spaslave2: 2</li></ul><p><strong>listeners</strong>  </p><ul><li>PLAINTEXT://spamaster:9092</li><li>PLAINTEXT://spaslave1:9092</li><li>PLAINTEXT://spaslave2:9092</li></ul><p><strong>advertised.listeners</strong></p><ul><li>advertised.listeners=PLAINTEXT://spamaster:9092</li><li>advertised.listeners=PLAINTEXT://spaslave1:9092</li><li>advertised.listeners=PLAINTEXT://spaslave2:9092</li></ul><h2 id="4-集群启动和测试"><a href="#4-集群启动和测试" class="headerlink" title="4. 集群启动和测试"></a>4. 集群启动和测试</h2><p>首先保证zookeeper集群正常启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh -daemon config/server.properties</span><br></pre></td></tr></table></figure></p><p>三个节点均要启动</p><p>创建topic test，test的 分区、副本为2<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper spamaster:2181,spaslave1:2181,spaslave2:2181 --replication-factor 2 --partitions 2 --topic test</span><br></pre></td></tr></table></figure></p><p>查看topic列表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --zookeeperspamaster:2181,spaslave1:2181,spaslave2:2181</span><br></pre></td></tr></table></figure></p><p>查看topic状态<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --describe --zookeeper spamaster:2181,spaslave1:2181,spaslave2:2181 --topic test</span><br></pre></td></tr></table></figure></p><blockquote><p>可以通过不同节点生产，消费消息来验证集群是否搭建成功</p></blockquote><p>生产消息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list spamaster:9092 --topic test</span><br></pre></td></tr></table></figure></p><p>消费消息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --zookeeper spamaster:2181,spaslave1:2181,spaslave2:2181 --topic test --from-beginning</span><br></pre></td></tr></table></figure></p><p>删除topic<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --delete --zookeeper spamaster:2181,spaslave1:2181,spaslave2:2181 --topic test</span><br></pre></td></tr></table></figure></p><p>关闭kafka<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure></p><h1 id="Flume搭建"><a href="#Flume搭建" class="headerlink" title="Flume搭建"></a>Flume搭建</h1><p>Flume是Cloudera提供的一个高可用、高可靠、分布式的海量日志采集、聚合和传输的系统。Flume支持在日志系统中定制各类数据发送方用于收集数据，同时Flume提供对数据的简单处理，并将数据处理结果写入各种数据接收方的能力</p><h2 id="1-安装包下载和解压"><a href="#1-安装包下载和解压" class="headerlink" title="1.安装包下载和解压"></a>1.安装包下载和解压</h2><p>下载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/flume/1.8.0/apache-flume-1.8.0-bin.tar.gz</span><br></pre></td></tr></table></figure></p><p>解压<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-flume-1.8.0-bin.tar.gz</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv apache-flume-1.8.0-bin /home/hadoop/bigdata/flume</span><br></pre></td></tr></table></figure><h2 id="2-环境变量配置"><a href="#2-环境变量配置" class="headerlink" title="2.环境变量配置"></a>2.环境变量配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br></pre></td></tr></table></figure><p>在文件中加入</p><blockquote><p>export FLUME_HOME=/home/hadoop/bigdata/flume</p></blockquote><blockquote><p>export PATH=$PATH:$FLUME_HOME/bin </p></blockquote><p>保存退出,执行source命令，使环境变量生效<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure></p><h2 id="3-flume节点配置"><a href="#3-flume节点配置" class="headerlink" title="3.flume节点配置"></a>3.flume节点配置</h2><h5 id="1-对conf路径下的flume-env-sh文件进行修改，加入java环境变量"><a href="#1-对conf路径下的flume-env-sh文件进行修改，加入java环境变量" class="headerlink" title="1.对conf路径下的flume-env.sh文件进行修改，加入java环境变量"></a>1.对conf路径下的flume-env.sh文件进行修改，加入java环境变量</h5><blockquote><p>export JAVA_HOME=/home/hadoop/bigdata/java</p></blockquote><h5 id="2-针对不同的sink对象，即日志收集到何处，设置不同的接收器配置文件"><a href="#2-针对不同的sink对象，即日志收集到何处，设置不同的接收器配置文件" class="headerlink" title="2.针对不同的sink对象，即日志收集到何处，设置不同的接收器配置文件"></a>2.针对不同的sink对象，即日志收集到何处，设置不同的接收器配置文件</h5><h6 id="1-在conf目录下新建flume-hdfs-conf配置文件，指定flume收集的日志写入到hdfs中"><a href="#1-在conf目录下新建flume-hdfs-conf配置文件，指定flume收集的日志写入到hdfs中" class="headerlink" title="1.在conf目录下新建flume-hdfs.conf配置文件，指定flume收集的日志写入到hdfs中"></a>1.在conf目录下新建flume-hdfs.conf配置文件，指定flume收集的日志写入到hdfs中</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"> 1 #agent1 name</span><br><span class="line"> 2 agent1.sources=source1</span><br><span class="line"> 3 agent1.sinks=sink1</span><br><span class="line"> 4 agent1.channels=channel1</span><br><span class="line"> 5 #Spooling Directory</span><br><span class="line"> 6 #set source1 spoolDir指定使用spool源路径，即flume监听信息源的路径</span><br><span class="line"> 7 agent1.sources.source1.type=spooldir</span><br><span class="line"> 8 agent1.sources.source1.spoolDir=/home/hadoop/bigdata/flume/flumetest/dir/logdfs</span><br><span class="line"> 9 agent1.sources.source1.channels=channel1</span><br><span class="line">10 agent1.sources.source1.fileHeader = false</span><br><span class="line">11 agent1.sources.source1.interceptors = i1</span><br><span class="line">12 agent1.sources.source1.interceptors.i1.type = timestamp</span><br><span class="line">13 #set sink1 日志文件收集到hdfs /flume/logdfs 路径下</span><br><span class="line">14 agent1.sinks.sink1.type=hdfs</span><br><span class="line">15 agent1.sinks.sink1.hdfs.path=hdfs://spamaster:9000/flume/logdfs</span><br><span class="line">16 agent1.sinks.sink1.hdfs.fileType=DataStream</span><br><span class="line">17 agent1.sinks.sink1.hdfs.writeFormat=TEXT</span><br><span class="line">18 agent1.sinks.sink1.hdfs.rollInterval=1</span><br><span class="line">19 agent1.sinks.sink1.channel=channel1</span><br><span class="line">20 agent1.sinks.sink1.hdfs.filePrefix=%Y-%m-%d</span><br><span class="line">21 agent1.sinks.sink1.hdfs.fileSuffix=.txt</span><br><span class="line">22 #set channel1</span><br><span class="line">23 agent1.channels.channel1.type=file</span><br><span class="line">24 agent1.channels.channel1.checkpointDir=/home/hadoop/bigdata/flume/flumetest/dir/logdfstmp/point</span><br><span class="line">25 agent1.channels.channel1.dataDirs=/home/hadoop/bigdata/flume/flumetest/dir/logdfstmp</span><br></pre></td></tr></table></figure><p>在flume路径下启动flume，指定以flume-hdfs.conf配置文件启动，命令中的agent1表示配置文件中的Agent的Name</p><blockquote><p>bin/flume-ng agent –conf conf –conf-file conf/flume-hdfs.conf –name agent1 -Dflume.root.logger=INFO,console</p></blockquote><p>在/home/hadoop/bigdata/flume/flumetest/dir/logdfs路径下导入一个文件test.log，该log文件会被flume检测到，在文件名后添加.COMPLETED后缀并上传到hdfs</p><h6 id="2-在conf目录下新建flume-kafka-conf配置文件，指定flume收集的日志写入到kafka中"><a href="#2-在conf目录下新建flume-kafka-conf配置文件，指定flume收集的日志写入到kafka中" class="headerlink" title="2.在conf目录下新建flume-kafka.conf配置文件，指定flume收集的日志写入到kafka中"></a>2.在conf目录下新建flume-kafka.conf配置文件，指定flume收集的日志写入到kafka中</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"> 1 # 指定Agent的组件名称  </span><br><span class="line"> 2 agent1.sources = source1</span><br><span class="line"> 3 agent1.sinks = sink1</span><br><span class="line"> 4 agent1.channels = channel1</span><br><span class="line"> 5 </span><br><span class="line"> 6 # 指定Flume source(要监听的路径)  </span><br><span class="line"> 7 agent1.sources.source1.type = spooldir</span><br><span class="line"> 8 agent1.sources.source1.spoolDir = /home/hadoop/bigdata/flume/flumetest/dir/logkafka</span><br><span class="line"> 9 agent1.sources.source1.ignorePattern = ^(.)*\\.tmp$</span><br><span class="line">10 </span><br><span class="line">11 # 指定Flume sink  </span><br><span class="line">12 # agent1.sinks.sink1.type = logger  </span><br><span class="line">13 agent1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">14 agent1.sinks.sink1.topic = callstatus</span><br><span class="line">15 agent1.sinks.sink1.brokerList = 192.168.2.198:9092,192.168.2.161:9092</span><br><span class="line">16 agent1.sinks.sink1.requiredAcks = 1</span><br><span class="line">17 agent1.sinks.sink1.batchSize = 16384</span><br><span class="line">18 </span><br><span class="line">19 # 指定Flume channel  </span><br><span class="line">20 agent1.channels.channel1.type=file</span><br><span class="line">21 agent1.channels.channel1.checkpointDir=/home/hadoop/bigdata/flume/flumetest/dir/logkafkatmp/point</span><br><span class="line">22 agent1.channels.channel1.dataDirs=/home/hadoop/bigdata/flume/flumetest/dir/logkafkatmp</span><br><span class="line">23 </span><br><span class="line">24 # 绑定source和sink到channel上  </span><br><span class="line">25 agent1.sources.source1.channels = channel1</span><br><span class="line">26 agent1.sinks.sink1.channel = channel1</span><br></pre></td></tr></table></figure><p> 启动flume</p><blockquote><p>bin/flume-ng agent –conf conf –conf-file conf/flume-kafka.conf –name agent1 -Dflume.root.logger=INFO,console</p></blockquote><p>启动kafka消费者</p><blockquote><p>bin/kafka-console-consumer.sh –zookeeper spamaster:2181,spaslave1:2181,spaslave2:2181 –topic callstatus –from-beginning</p></blockquote><p>在/home/hadoop/bigdata/flume/flumetest/dir/logkafka路径下导入文件，立即被kafka所消费，通过消费者程序消费flume配置中设置的topic可以看到，文件内容已经传到kafka中了</p><blockquote><p>Spool用于监测配置的目录下新增的文件，并将文件中的数据读取出来。需要注意两点：拷贝到spool目录下的文件不可以再打开编辑(这样收集到的日志内容为空，编辑的内容无效）、spool目录下不可包含相应的子目录。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Kafka集群搭建&quot;&gt;&lt;a href=&quot;#Kafka集群搭建&quot; class=&quot;headerlink&quot; title=&quot;Kafka集群搭建&quot;&gt;&lt;/a&gt;Kafka集群搭建&lt;/h1&gt;&lt;h2 id=&quot;1-kafka基本结构&quot;&gt;&lt;a href=&quot;#1-kafka基本结构&quot; class=&quot;headerlink&quot; title=&quot;1. kafka基本结构&quot;&gt;&lt;/a&gt;1. kafka基本结构&lt;/h2&gt;&lt;p&gt;作为一个消息系统，其基本结构中至少要有产生消息的组件（消息生产者，Producer）以及消费消息的组件（消费者，Consumer)。生产者负责生产消息，将消息写入Kafka集群;消费者从Kafka 集群中拉取消息。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
